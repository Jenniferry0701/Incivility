{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CrESLdfftlMr",
        "outputId": "692760c9-5624-4b5f-cf17-ec2f5fcc44ce"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "print(torch.__version__)\n",
        "import pandas as pd\n",
        "!pip install transformers\n",
        "from transformers import BertTokenizer\n",
        "import sys, time, datetime, random\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "import numpy as np\n",
        "\n",
        "# Metrics\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import matthews_corrcoef\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "import gc\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "id": "_q5mce7WtvcB",
        "outputId": "9d55d38e-307a-4858-95d4-d8429494da61"
      },
      "outputs": [],
      "source": [
        "if torch.cuda.is_available():\n",
        "\n",
        "    # Tell PyTorch to use the GPU.\n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "# only use when using google colab\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17,
          "referenced_widgets": [
            "c2d987de25b647e6a37faf5e4568f8da",
            "2fd4c41d84684d1d83347b65f03e6876",
            "a179bb9b77fd41a3abbaf872d2fb48ff",
            "f2f2d791eed44f42992d5b8be7548a83",
            "ab9aec9ff9cb42c1b87dd61b314bd749",
            "fd7f16ff553644d7aa4417df1aa2e6bd",
            "ef035f8849f749b4aeb858cbf5aa0aca",
            "4eb74448c4fa4047870077499f718f05",
            "dfd3f3db9bd9421bb50398f51fa79f8b",
            "fe0b3ef0c853434aa7ec90e0a6dc0926",
            "e5015dd930e548b3ba5e9de78299be43",
            "27af2122f2a64e4ca5c4a24afed66523",
            "4f230dc6e9164f56bfc25a39c3e46328",
            "703ac4ede584485e9266ffb24ca679e9",
            "2fc90064123944e99f595ad2419c2fc6",
            "614a83cca76c4cf1a95d647b644233f3",
            "bf1cabd964e54b888783a9945e2d4d67",
            "61092cd06de7443fb5c7cab06cad7053",
            "89b08bf7e943486da246adb636cfc41e",
            "05b1fc504bc24d91b7a0e17f4d5b66d6",
            "941fc1daa1eb40dbabb58225705388e6",
            "dfd73627ead44fc9a900fca628a723c7",
            "2c848615a59d45d39c2069b68f6f00c4",
            "701f3bf749c6433cb8d506520e89624a",
            "3b7052f0e506434e92d01031b5bf6d09",
            "953f46ea50bf4fedbf3cc1407b5d4531",
            "61df7fe5321c4872bb1e9374a108e9cd",
            "41d92ca5b42644be92bbf78422747d04",
            "77d6ffe9199945ecaa08dde9c5c5785d",
            "e0aa2cda97ee4a3da7f96e56b391c8cd",
            "d2c304b04aeb4fbcb415abe88040acff",
            "1ea4f7db08f84690a22434464c69863c",
            "f626f1da97bb4f219a222454aa9c2d01"
          ]
        },
        "id": "VJF69Lohi_-w",
        "outputId": "8152ea26-fbf5-4ae3-e7f7-f4b2a3b34a54"
      },
      "outputs": [],
      "source": [
        "MAX_LEN = 512\n",
        "\n",
        "sentence_lengths = []\n",
        "def tokenize_and_count(s, lst, max_len):\n",
        "    answer = tokenizer.encode(s, add_special_tokens=True)\n",
        "    lst.append(len(answer))\n",
        "    return answer\n",
        "\n",
        "def preprocess_context_bert(df, text_col_name, context_col_name, prefix='concat_'):\n",
        "  contexts = df[context_col_name].apply(lambda s : tokenize_and_count(s, sentence_lengths, MAX_LEN))\n",
        "  comments = df[text_col_name].apply(lambda s : tokenize_and_count(s, sentence_lengths, MAX_LEN))\n",
        "  print(len(contexts), len(comments), contexts[0])\n",
        "  df[prefix + 'bert'] = [context + comment[1:] for context, comment in zip(contexts, comments)]\n",
        "  print(len(contexts + comments[1:]))\n",
        "  df[prefix + 'type_id'] = [[0] * len(context) + [1] * len(comment[1:]) for context, comment in zip(contexts, comments)]\n",
        "  df[prefix + 'bert'] = pad_sequences(df[prefix + 'bert'].values, maxlen=MAX_LEN, dtype=\"long\", \n",
        "                          value=0, truncating=\"post\", padding=\"post\").tolist()\n",
        "  df[prefix + 'type_id'] = pad_sequences(df[prefix + 'type_id'].values, maxlen=MAX_LEN, dtype=\"long\", \n",
        "                          value=0, truncating=\"post\", padding=\"post\").tolist()\n",
        "  df[prefix + 'attention'] = df[prefix + 'bert'].apply(lambda arr : [int(token_id > 0) for token_id in arr])\n",
        "\n",
        "def preprocess_bert(df, text_col_name, prefix=''):\n",
        "  df[prefix + 'bert'] = df[text_col_name].apply(lambda s : tokenize_and_count(s, sentence_lengths, MAX_LEN))\n",
        "  df[prefix + 'bert'] = pad_sequences(df[prefix + 'bert'].values, maxlen=MAX_LEN, dtype=\"long\", \n",
        "                          value=0, truncating=\"post\", padding=\"post\").tolist()\n",
        "  df[prefix + 'attention'] = df[prefix + 'bert'].apply(lambda arr : [int(token_id > 0) for token_id in arr])\n",
        "  df[prefix + 'type_id'] = df[prefix + 'bert'].apply(lambda arr : [0 for token_id in arr])\n",
        "  df[prefix + 'type_id'] = pad_sequences(df[prefix + 'type_id'].values, maxlen=MAX_LEN, dtype=\"long\", \n",
        "                          value=0, truncating=\"post\", padding=\"post\").tolist()\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1qgFB_g4Jp51"
      },
      "source": [
        "Civility Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YloseN1CYGcy"
      },
      "outputs": [],
      "source": [
        "categories = ['stereotype', 'namecalling', 'aspersion', 'demeaning', 'vulgarity', 'personal_attack', 'third_party_attack', 'civility']\n",
        "columns = ['id', 'comment', 'parent_comment', 'original_post', 'divisiveness','divisiveness_keyword','human_incivility',\n",
        "            'stereotype','namecalling','aspersion', 'demeaning','vulgarity','other']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QU1Eybvgga6s",
        "outputId": "0be72924-ae4f-4926-cd6d-7c9787f2d011"
      },
      "outputs": [],
      "source": [
        "annotated_data_dir = 'data/labeled/final_annotated_data_incivility_3030.pickle'\n",
        "annotated_df = pd.read_pickle(annotated_data_dir)\n",
        "annotated_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 511
        },
        "id": "pI_u_kXOjira",
        "outputId": "e17c8bbf-7281-4d49-a073-c1811da8f93f"
      },
      "outputs": [],
      "source": [
        "# Aggregate Raw Annotations\n",
        "annotated_df['personal_attack'] = ((annotated_df['namecalling'] == 1) | (annotated_df['namecalling'] == 2) | (annotated_df['demeaning'] == 1)).astype(int)\n",
        "annotated_df['third_party_attack'] = ((annotated_df['namecalling'] == 3)).astype(int)\n",
        "annotated_df['other']=annotated_df['other'].apply(lambda x: 1 if str(type(x))==\"<class 'str'>\" else x)\n",
        "annotated_df['civility'] = annotated_df['stereotype'].astype(int) + annotated_df['aspersion'].astype(int) + annotated_df['demeaning'].astype(int) + annotated_df['vulgarity'].astype(int) + annotated_df['namecalling'].astype(int)  + annotated_df['other'].astype(int)\n",
        "\n",
        "# special treatment for stereotype data\n",
        "annotated_df.stereotype = annotated_df.stereotype.astype(bool).astype(int)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "optionally, we have a baseline model that concatenate the context and the actual comments, uncomment the following"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PJtsfMkOxlBk"
      },
      "outputs": [],
      "source": [
        "# annotated_df['concat_comment'] = annotated_df['parent_comment'] + ' [SEP] ' + annotated_df['comment']\n",
        "# preprocess_context_bert(annotated_df, 'comment_aug', 'parent_comment_aug', 'aug_concat_')\n",
        "# preprocess_bert(annotated_df, 'comment_aug', 'aug_')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PmaMQP7cDZI1"
      },
      "outputs": [],
      "source": [
        "# aug_train_df, aug_test_df = train_test_split(df, random_state=42, test_size=test_size)\n",
        "# aug_train_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BDxOrJgH-iOU",
        "outputId": "dd3d0f4a-87e1-42bb-bab5-2226a20e7c2f"
      },
      "outputs": [],
      "source": [
        "test_size = 0.2\n",
        "validation_size = 0.5\n",
        "train_df, test_df = train_test_split(annotated_df, random_state=42, test_size=test_size, stratify=annotated_df.namecalling.values)\n",
        "test_df, validation_df = train_test_split(test_df, random_state=42, test_size=validation_size)\n",
        "\n",
        "\n",
        "print(f\"\"\"{1 - test_size}/{test_size * (1-validation_size)}/{test_size * validation_size} split\n",
        "{train_df.shape[0]} lines of training data,\n",
        "{test_df.shape[0]} lines of test data\n",
        "{validation_df.shape[0]} lines of validation data\"\"\")\n",
        "\n",
        "# temp_data_dir = './data/labeled/temp/'\n",
        "# train_df.to_pickle(temp_data_dir, os.path.join('train_df.pickle'))\n",
        "# validation_df.to_pickle(temp_data_dir, os.path.join('validation_df.pickle'))\n",
        "# test_df.to_pickle(temp_data_dir, os.path.join('test_df.pickle'))\n",
        "\n",
        "print(f\"\"\"{1 - test_size}/{test_size * (1-validation_size)}/{test_size * validation_size} split\n",
        "{train_df.shape[0]} lines of training data,\n",
        "{test_df.shape[0]} lines of test data\n",
        "{validation_df.shape[0]} lines of validation data\"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W34dzGnSoUMv"
      },
      "outputs": [],
      "source": [
        "# split train, test for stereotypes\n",
        "\n",
        "train_df_pos = train_df[train_df['stereotype'] == 1]\n",
        "train_df_neg = train_df[train_df['stereotype'] == 0].sample(len(train_df_pos)*4)\n",
        "train_df = pd.concat([train_df_pos, train_df_neg])\n",
        "\n",
        "\n",
        "_, test_df = train_test_split(train_df, random_state=42, test_size=0.2, stratify=train_df.stereotype.values)\n",
        "print(len(train_df), len(test_df))\n",
        "validation_df, test_df = train_test_split(test_df, random_state=42, test_size=0.5)\n",
        "\n",
        "print(len(train_df), len(test_df), len(validation_df))\n",
        "\n",
        "validation_df.stereotype.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hef7Uz6bwAyt"
      },
      "outputs": [],
      "source": [
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    try:\n",
        "        roc = roc_auc_score(pred_flat, labels_flat)\n",
        "    except ValueError:\n",
        "        roc = 0\n",
        "    return f1_score(pred_flat, labels_flat, average='weighted'), roc, np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
        "\n",
        "def _flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "\n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n",
        "\n",
        "def run_evaluation(model, test_x, test_labels, test_masks, test_type, batch_size, verbose=False):\n",
        "    if verbose:\n",
        "        print(f\"{list(test_labels).count(1)} positive samples out of {len(test_labels)} total lines\")\n",
        "        print('Predicting labels for {:,} test sentences...'.format(len(test_x)))\n",
        "    \n",
        "    test_data = TensorDataset(test_x, test_masks, test_labels, test_type)\n",
        "    test_sampler = SequentialSampler(test_data)\n",
        "    test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)\n",
        "    \n",
        "    # Put model in evaluation mode\n",
        "    model.eval()\n",
        "    \n",
        "    # Tracking variables \n",
        "    predictions , true_labels = [], []\n",
        "\n",
        "    # Predict \n",
        "    for batch in test_dataloader:\n",
        "        # Add batch to GPU\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "\n",
        "        # Unpack the inputs from our dataloader\n",
        "        b_input_ids, b_input_mask, b_labels, b_type_ids = batch\n",
        "\n",
        "        # Telling the model not to compute or store gradients, saving memory and \n",
        "        # speeding up prediction\n",
        "        with torch.no_grad():\n",
        "          # Forward pass, calculate logit predictions\n",
        "          outputs = model(b_input_ids, token_type_ids=b_type_ids, \n",
        "                          attention_mask=b_input_mask)\n",
        "\n",
        "        logits = outputs[0]\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # Store predictions and true labels\n",
        "        predictions.append(logits)\n",
        "        true_labels.append(label_ids)\n",
        "        \n",
        "    # Create results\n",
        "    matthews_set = []\n",
        "\n",
        "    # Evaluate each test batch using Matthew's correlation coefficient\n",
        "    if verbose:\n",
        "        print('Calculating Matthews Corr. Coef. for each batch...')\n",
        "\n",
        "    # For each input batch...\n",
        "    for i in range(len(true_labels)):\n",
        "        # The predictions for this batch are a 2-column ndarray (one column for \"0\" \n",
        "        # and one column for \"1\"). Pick the label with the highest value and turn this\n",
        "        # in to a list of 0s and 1s.\n",
        "        pred_labels_i = np.argmax(predictions[i], axis=1).flatten()\n",
        "        # Calculate and store the coef for this batch.  \n",
        "        matthews = matthews_corrcoef(true_labels[i], pred_labels_i)\n",
        "        \n",
        "        if verbose:\n",
        "            print(\"Predicted Label for Batch \" + str(i) + \" is \" + str(pred_labels_i))\n",
        "            print(\"True Label for Batch \" + str(i) + \" is \" + str(true_labels[i])) \n",
        "            print(\"Matthew's correlation coefficient for Batch \" + str(i) + \" is \" + str(matthews))\n",
        "        matthews_set.append(matthews)\n",
        "    \n",
        "    # Combine the predictions for each batch into a single list of 0s and 1s.\n",
        "    flat_predictions = [item for sublist in predictions for item in sublist]\n",
        "    flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
        "\n",
        "    # Combine the correct labels for each batch into a single list.\n",
        "    flat_true_labels = [item for sublist in true_labels for item in sublist]\n",
        "\n",
        "    diff = []\n",
        "    for i in range(len(flat_true_labels)):\n",
        "      if flat_true_labels[i] != flat_predictions[i]:\n",
        "        diff.append(i)\n",
        "\n",
        "    # Calculate the MCC\n",
        "    acc = accuracy_score(flat_predictions, flat_true_labels)\n",
        "    mcc = matthews_corrcoef(flat_true_labels, flat_predictions)\n",
        "    f1 = f1_score(flat_true_labels, flat_predictions, average='weighted')\n",
        "    ra = roc_auc_score(flat_true_labels, flat_predictions)\n",
        "\n",
        "    cm = confusion_matrix(flat_true_labels, flat_predictions)\n",
        "    sns.heatmap(cm, annot=True, cmap='Blues', fmt='g')\n",
        "\n",
        "    print('MCC: %.3f' % mcc)\n",
        "    print('ROC_AUC: %.3f' % ra)\n",
        "    print('F1: %.3f' % f1)\n",
        "    print('Accuracy: %.3f' % acc)\n",
        "    print(classification_report(flat_true_labels, flat_predictions))\n",
        "\n",
        "    return diff\n",
        "\n",
        "def train(model, epochs, train_dataloader, test_dataloader, optimizer, scheduler, seed_val=42):\n",
        "    # This training code is based on the `run_glue.py` script here:\n",
        "    # https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "    # Set the seed value all over the place to make this reproducible.\n",
        "    random.seed(seed_val)\n",
        "    np.random.seed(seed_val)\n",
        "    torch.manual_seed(seed_val)\n",
        "    torch.cuda.manual_seed_all(seed_val)\n",
        "    \n",
        "    # Store the average loss after each epoch so we can plot them.\n",
        "    training_losses = []\n",
        "    testing_losses = []\n",
        "    f1s = []\n",
        "\n",
        "    for epoch_i in range(0, epochs):\n",
        "        # ========================================\n",
        "        #               Training\n",
        "        # ========================================\n",
        "\n",
        "        # Perform one full pass over the training set.\n",
        "        print(\"\")\n",
        "        print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "        print('Training...')\n",
        "        \n",
        "        # Measure how long the training epoch takes.\n",
        "        t0 = time.time()\n",
        "\n",
        "        # Reset the total loss for this epoch.\n",
        "        total_train_loss = 0\n",
        "\n",
        "        # Put the model into training mode.\n",
        "        model.train()\n",
        "        \n",
        "        # For each batch of training data...\n",
        "        for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "            if step % 40 == 0 and not step == 0:\n",
        "                elapsed = format_time(time.time() - t0)\n",
        "\n",
        "                # Report progress.\n",
        "                print(f'  Batch {step:>5,}  of  {len(train_dataloader):>5,}.    Elapsed: {elapsed:}.')\n",
        "\n",
        "            # `batch` contains three pytorch tensors:\n",
        "            #   [0]: input ids \n",
        "            #   [1]: attention masks\n",
        "            #   [2]: labels \n",
        "            b_input_ids = batch[0].to(device)\n",
        "            b_input_mask = batch[1].to(device)\n",
        "            b_labels = batch[2].to(device)\n",
        "            b_type_ids = batch[3].to(device)\n",
        "\n",
        "\n",
        "            model.zero_grad()        \n",
        "\n",
        "            outputs = model(b_input_ids, \n",
        "                        token_type_ids=b_type_ids, \n",
        "                        attention_mask=b_input_mask, \n",
        "                        labels=b_labels)\n",
        "            \n",
        "            loss = outputs[0]\n",
        "\n",
        "            total_train_loss += loss.item()\n",
        "\n",
        "            loss.backward()\n",
        "\n",
        "            # Clip the norm of the gradients to 1.0.\n",
        "            # This is to help prevent the \"exploding gradients\" problem.\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "            # Update parameters and take a step using the computed gradient.\n",
        "            optimizer.step()\n",
        "\n",
        "            # Update the learning rate.\n",
        "            scheduler.step()\n",
        "        \n",
        "        # Calculate the average loss over the training data.\n",
        "        avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "        training_losses.append(avg_train_loss)\n",
        "        \n",
        "        print(\"\")\n",
        "        print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "        print(\"  Training epoch took: {:}\".format(format_time(time.time() - t0)))\n",
        "        \n",
        "        # ========================================\n",
        "        #               Validation\n",
        "        # ========================================\n",
        "        # After the completion of each training epoch, measure our performance on\n",
        "        # our validation set.\n",
        "\n",
        "        print(\"\")\n",
        "        print(\"Running Validation...\")\n",
        "        \n",
        "        # Measure how long the testing takes.\n",
        "        t0 = time.time()\n",
        "\n",
        "        # Reset the total loss for this epoch.\n",
        "        total_test_loss = 0\n",
        "\n",
        "        # Put the model in evaluation mode--the dropout layers behave differently\n",
        "        # during evaluation.\n",
        "        model.eval()\n",
        "\n",
        "        # Tracking variables \n",
        "        eval_loss, eval_accuracy, eval_f1, eval_auc = 0, 0, 0, 0\n",
        "        nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "        # Evaluate data for one epoch\n",
        "        for batch in test_dataloader:\n",
        "\n",
        "            # Add batch to GPU\n",
        "            batch = tuple(t.to(device) for t in batch)\n",
        "\n",
        "            # Unpack the inputs from our dataloader\n",
        "            b_input_ids, b_input_mask, b_labels, b_type_ids = batch\n",
        "\n",
        "            # Telling the model not to compute or store gradients, saving memory and\n",
        "            # speeding up validation\n",
        "            with torch.no_grad():        \n",
        "                outputs = model(b_input_ids, \n",
        "                                token_type_ids=b_type_ids, \n",
        "                                attention_mask=b_input_mask, \n",
        "                                labels=b_labels)\n",
        "            loss = outputs[0]\n",
        "\n",
        "            total_test_loss += loss.item()\n",
        "\n",
        "            logits = outputs[1]\n",
        "\n",
        "            # Move logits and labels to CPU\n",
        "            logits = logits.detach().cpu().numpy()\n",
        "            label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "            # Calculate the accuracy for this batch of test sentences.\n",
        "            tmp_eval_f1, tmp_eval_auc, tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "\n",
        "            # Accumulate the total accuracy.\n",
        "            eval_accuracy += tmp_eval_accuracy\n",
        "            eval_f1 += tmp_eval_f1\n",
        "            eval_auc += tmp_eval_auc\n",
        "            # Track the number of batches\n",
        "            nb_eval_steps += 1\n",
        "\n",
        "        avg_test_loss = total_test_loss / len(test_dataloader)            \n",
        "        testing_losses.append(avg_test_loss)\n",
        "        f1s.append(eval_f1/nb_eval_steps)\n",
        "\n",
        "        # Report the final accuracy for this validation run.\n",
        "        print(\"  F1 Score: {0:.2f}\".format(eval_f1/nb_eval_steps))\n",
        "        print(\"  ROC_AUC: {0:.2f}\".format(eval_auc/nb_eval_steps))\n",
        "        print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
        "        print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
        "        print(\"  Average validation loss: {0:.2f}\".format(avg_test_loss))\n",
        "        \n",
        "    return model, training_losses, testing_losses, f1s\n",
        "\n",
        "def draw_test_train_curve(test_losses, train_losses):\n",
        "    # Use plot styling from seaborn.\n",
        "    sns.set(style='darkgrid')\n",
        "\n",
        "    # Increase the plot size and font size.\n",
        "    sns.set(font_scale=1.5)\n",
        "    plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "    # Plot the learning curve.\n",
        "    plt.plot(train_losses, 'b-o', label='Train')\n",
        "    plt.plot(test_losses, 'r-o', label='Test')\n",
        "\n",
        "    # Label the plot.\n",
        "    plt.title(f\"Train/Test loss\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.legend()\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "jMFUUgguy__Z",
        "outputId": "018836f6-1962-413c-a7d4-5c6309ddb110"
      },
      "outputs": [],
      "source": [
        "batch_size=16\n",
        "gpu_id=0\n",
        "epochs =10\n",
        "lr = 1e-5 # TODO: fine tuning the models were manual for me before\n",
        "\n",
        "# def eval_test_site\n",
        "def single_category_train(train_df, validation_df, test_df, category, prefix=''):\n",
        "\n",
        "\n",
        "  train_x = train_df[prefix+'bert'].values.tolist()\n",
        "  train_y = train_df[category].values.astype(int).astype(bool).astype(int).tolist()\n",
        "  train_masks = train_df[prefix+'attention'].values.tolist()\n",
        "  train_type = train_df[prefix+'type_id'].values.tolist()\n",
        "\n",
        "  # Create x, y for each\n",
        "  train_x = torch.tensor(train_x)\n",
        "  val_x = torch.tensor(validation_df[prefix+'bert'].values.tolist())\n",
        "  test_x = torch.tensor(test_df[prefix+'bert'].values.tolist())\n",
        "\n",
        "  train_masks = torch.tensor(train_masks)\n",
        "  val_masks = torch.tensor(validation_df[prefix+'attention'].values.tolist())\n",
        "  test_masks = torch.tensor(test_df[prefix+'attention'].values.tolist())\n",
        "\n",
        "  train_y = torch.tensor(train_y)\n",
        "  val_y = torch.tensor(validation_df[category].values.astype(int).astype(bool).astype(int))\n",
        "  test_y = torch.tensor(test_df[category].values.astype(int).astype(bool).astype(int))\n",
        "\n",
        "  train_type = torch.tensor(train_type)\n",
        "  val_type = torch.tensor(validation_df[prefix+'type_id'].values.tolist())\n",
        "  test_type = torch.tensor(test_df[prefix+'type_id'].values.tolist())\n",
        "\n",
        "  print(len(train_x), len(train_masks), len(train_y), len(train_type))\n",
        "\n",
        "  # Create DataLoaders for train data and test data\n",
        "  train_data = TensorDataset(train_x, train_masks, train_y, train_type)\n",
        "  train_sampler = RandomSampler(train_data)\n",
        "  train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "  val_data = TensorDataset(val_x, val_masks, val_y, val_type)\n",
        "  val_sampler = RandomSampler(val_data)\n",
        "  val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)\n",
        "\n",
        "  test_data = TensorDataset(test_x, test_masks, test_y, test_type)\n",
        "  test_sampler = SequentialSampler(test_data)\n",
        "  test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)\n",
        "\n",
        "  print(len(list(train_dataloader)))\n",
        "\n",
        "\n",
        "  model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
        "    num_labels = 2, # The number of output labels--2 for binary classification.\n",
        "                    # You can increase this for multi-class tasks.   \n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = True, # Whether the model returns all hidden-states.\n",
        "  )\n",
        "\n",
        "  print(device)\n",
        "  model.cuda(device=device)\n",
        "\n",
        "  optimizer = AdamW(model.parameters(),\n",
        "                lr = lr, # args.learning_rate - default is 5e-5\n",
        "                eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "              )\n",
        "\n",
        "  # Total number of training steps is [number of batches] x [number of epochs]. \n",
        "  total_steps = len(train_dataloader) * epochs\n",
        "  scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                              num_warmup_steps = 0,\n",
        "                                              num_training_steps = total_steps)\n",
        "\n",
        "  model, train_losses, test_losses, f1s = train(model, epochs,\n",
        "                                                  train_dataloader,\n",
        "                                                  val_dataloader,\n",
        "                                                  optimizer,\n",
        "                                                  scheduler,\n",
        "                                                  seed_val=42)\n",
        "\n",
        "  # Visualize test and train curve\n",
        "  draw_test_train_curve(test_losses, train_losses)\n",
        "\n",
        "    # Evaluation results\n",
        "  print(\"====================\")\n",
        "  print(\"====================\")\n",
        "  print(\"EVALUATION\")\n",
        "  diff = run_evaluation(model, test_x, test_y, test_masks,  test_type, batch_size, verbose=False)\n",
        "  print(f\"lr = {lr}: {f1s}\")\n",
        "  print(diff)\n",
        "\n",
        "  return model\n",
        "\n",
        "for c in categories:\n",
        "  gc.collect()\n",
        "  torch.cuda.empty_cache()\n",
        "  model = single_category_train(train_df, validation_df, test_df, c, '')\n",
        "  model_name = \"{}_{}_{}_3000\".format(c, lr, epochs)\n",
        "  model.save_pretrained('./models/{}'.format(model_name))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 192
        },
        "id": "6PdZ3S4mMjVR",
        "outputId": "0461eef1-6070-46f1-e4ac-d898b4245c5d"
      },
      "outputs": [],
      "source": [
        "diff = run_evaluation(model, test_x, test_y, test_masks, batch_size, verbose=False)\n",
        "print(diff)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UG_GAdSqNcac"
      },
      "outputs": [],
      "source": [
        "diff = [9, 14, 15, 24, 25, 26, 27, 29, 30, 32, 50, 51, 56, 59, 64, 71, 78, 85, 86, 89, 91, 92, 94, 99, 102]\n",
        "\n",
        "print(len(test_df), len(diff))\n",
        "for i in range(len(test_df)):\n",
        "  if i in diff:\n",
        "    print(\"MISCLASSIFICATION\")\n",
        "    print(test_df.iloc[i]['comment'])\n",
        "    print(test_df.iloc[i]['parent_comment'])\n",
        "    print(test_df.iloc[i]['civility'])\n",
        "    for cat in ['stereotype', 'namecalling', 'demeaning', 'vulgarity', 'other']:\n",
        "      print(cat, test_df.iloc[i][cat])\n",
        "    print(test_df.iloc[i]['id'])\n",
        "    print('\\n\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "98QrSKhv8KI3"
      },
      "outputs": [],
      "source": [
        "lr_5e_05 = ('5e_05', [0.7776543005866313, 0.6067515817515817, 0.7134108164183353, 0.6517287751807875, 0.7459083633453382])\n",
        "lr_3e_05 = ('3e_05', [0.6232893157262904, 0.7727551020408162, 0.7434926602219836, 0.6489188657919307, 0.7466314731020613])\n",
        "lr_2e_05 = ('2e_05', [0.0, 0.49230769230769234, 0.458974358974359, 0.4025641025641026, 0.4717948717948718])\n",
        "lr_1e_05 = ('1e_05', [0.6545212956977663, 0.7439080760509332, 0.7513644588270091, 0.6913832199546485, 0.8059093812963782])\n",
        "lr_5e_06 = ('5e_06', [0.5877032324400746, 0.5989232989232989, 0.7007700049716857, 0.738501708151536, 0.7803312629399585])\n",
        "x = list(range(1, epochs + 1))\n",
        "\n",
        "\n",
        "for lr, y in [lr_5e_05, lr_3e_05, lr_2e_05, lr_1e_05, lr_5e_06]:\n",
        "    plt.plot(x, y, label=lr)\n",
        "plt.legend()\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('f1 score')\n",
        "plt.title('Hyperparameter Search')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c4a25eoLBlyq"
      },
      "outputs": [],
      "source": [
        "model_name = 'bert_1015+5000_2e_05'\n",
        "\n",
        "# model.save_pretrained('./models/{}'.format(model_name))\n",
        "# tokenizer.save_pretrained('./models/{}_tokenizer'.format(model_name))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The following function is separate from the model training, and is experimentally using BERT to create embedding for the texts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1QHbmXxoFOxQ"
      },
      "outputs": [],
      "source": [
        "def get_post_bert_repr(model, test_x, test_labels, test_masks, batch_size, verbose=False):\n",
        "    if verbose:\n",
        "        print(f\"{list(test_labels).count(1)} positive samples out of {len(test_labels)} total lines\")\n",
        "        print('Predicting labels for {:,} test sentences...'.format(len(test_x)))\n",
        "    \n",
        "    test_data = TensorDataset(test_x, test_masks, test_labels)\n",
        "    test_sampler = SequentialSampler(test_data)\n",
        "    test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)\n",
        "    \n",
        "    # Put model in evaluation mode\n",
        "    model.eval()\n",
        "    \n",
        "    # Tracking variables \n",
        "    predictions , true_labels,  = [], []\n",
        "    all_hidden_states_mean = []\n",
        "    # Predict \n",
        "    for batch in test_dataloader:\n",
        "        # Add batch to GPU\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "\n",
        "        # Unpack the inputs from our dataloader\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "        # Telling the model not to compute or store gradients, saving memory and \n",
        "        # speeding up prediction\n",
        "        with torch.no_grad():\n",
        "          # Forward pass, calculate logit predictions\n",
        "          outputs = model(b_input_ids, token_type_ids=None, \n",
        "                          attention_mask=b_input_mask)\n",
        "\n",
        "        logits = outputs[0]\n",
        "        hidden_states = (outputs[1])\n",
        "        hidden_states = hidden_states[1].cpu().numpy()\n",
        "        hidden_states_mean = hidden_states.mean(axis=1)\n",
        "        for hidden_state_mean in hidden_states_mean:\n",
        "          all_hidden_states_mean.append(hidden_state_mean)\n",
        "\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # Store predictions and true labels\n",
        "        predictions.append(logits)\n",
        "        true_labels.append(label_ids)\n",
        "      \n",
        "    return np.stack(all_hidden_states_mean)\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cTeQykC53lkA"
      },
      "outputs": [],
      "source": [
        "test_x = torch.tensor(annotated_df['bert'].values.tolist())\n",
        "\n",
        "test_masks = torch.tensor(annotated_df['attention'].values.tolist())\n",
        "\n",
        "test_y = torch.tensor(annotated_df.label.values.astype(int))\n",
        "\n",
        "test_data = TensorDataset(test_x, test_masks, test_y)\n",
        "test_sampler = SequentialSampler(test_data)\n",
        "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)\n",
        "\n",
        "reprs = get_post_bert_repr(model, test_x, test_y, test_masks, batch_size, verbose=False)\n",
        "print(reprs.shape)\n",
        "np.save('data/labeled_comment_reprs.npy', reprs)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "background_execution": "on",
      "collapsed_sections": [],
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.7 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "vscode": {
      "interpreter": {
        "hash": "0fb1c8c08560ef10633da472fe90b901e59287299349590425902f1ab2ccdd49"
      }
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "05b1fc504bc24d91b7a0e17f4d5b66d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "2.0.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1ea4f7db08f84690a22434464c69863c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "2.0.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "27af2122f2a64e4ca5c4a24afed66523": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "2.0.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4f230dc6e9164f56bfc25a39c3e46328",
              "IPY_MODEL_703ac4ede584485e9266ffb24ca679e9",
              "IPY_MODEL_2fc90064123944e99f595ad2419c2fc6"
            ],
            "layout": "IPY_MODEL_614a83cca76c4cf1a95d647b644233f3",
            "tabbable": null,
            "tooltip": null
          }
        },
        "2c848615a59d45d39c2069b68f6f00c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "2.0.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_701f3bf749c6433cb8d506520e89624a",
              "IPY_MODEL_3b7052f0e506434e92d01031b5bf6d09",
              "IPY_MODEL_953f46ea50bf4fedbf3cc1407b5d4531"
            ],
            "layout": "IPY_MODEL_61df7fe5321c4872bb1e9374a108e9cd",
            "tabbable": null,
            "tooltip": null
          }
        },
        "2fc90064123944e99f595ad2419c2fc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "2.0.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_941fc1daa1eb40dbabb58225705388e6",
            "placeholder": "​",
            "style": "IPY_MODEL_dfd73627ead44fc9a900fca628a723c7",
            "tabbable": null,
            "tooltip": null,
            "value": " 28.0/28.0 [00:00&lt;00:00, 668B/s]"
          }
        },
        "2fd4c41d84684d1d83347b65f03e6876": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "2.0.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_fd7f16ff553644d7aa4417df1aa2e6bd",
            "placeholder": "​",
            "style": "IPY_MODEL_ef035f8849f749b4aeb858cbf5aa0aca",
            "tabbable": null,
            "tooltip": null,
            "value": "Downloading vocab.txt: 100%"
          }
        },
        "3b7052f0e506434e92d01031b5bf6d09": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "2.0.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_e0aa2cda97ee4a3da7f96e56b391c8cd",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d2c304b04aeb4fbcb415abe88040acff",
            "tabbable": null,
            "tooltip": null,
            "value": 570
          }
        },
        "41d92ca5b42644be92bbf78422747d04": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "2.0.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4eb74448c4fa4047870077499f718f05": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "2.0.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f230dc6e9164f56bfc25a39c3e46328": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "2.0.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_bf1cabd964e54b888783a9945e2d4d67",
            "placeholder": "​",
            "style": "IPY_MODEL_61092cd06de7443fb5c7cab06cad7053",
            "tabbable": null,
            "tooltip": null,
            "value": "Downloading tokenizer_config.json: 100%"
          }
        },
        "61092cd06de7443fb5c7cab06cad7053": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "2.0.0",
          "model_name": "HTMLStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "614a83cca76c4cf1a95d647b644233f3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "2.0.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61df7fe5321c4872bb1e9374a108e9cd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "2.0.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "701f3bf749c6433cb8d506520e89624a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "2.0.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_41d92ca5b42644be92bbf78422747d04",
            "placeholder": "​",
            "style": "IPY_MODEL_77d6ffe9199945ecaa08dde9c5c5785d",
            "tabbable": null,
            "tooltip": null,
            "value": "Downloading config.json: 100%"
          }
        },
        "703ac4ede584485e9266ffb24ca679e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "2.0.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_89b08bf7e943486da246adb636cfc41e",
            "max": 28,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_05b1fc504bc24d91b7a0e17f4d5b66d6",
            "tabbable": null,
            "tooltip": null,
            "value": 28
          }
        },
        "77d6ffe9199945ecaa08dde9c5c5785d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "2.0.0",
          "model_name": "HTMLStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "89b08bf7e943486da246adb636cfc41e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "2.0.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "941fc1daa1eb40dbabb58225705388e6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "2.0.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "953f46ea50bf4fedbf3cc1407b5d4531": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "2.0.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_1ea4f7db08f84690a22434464c69863c",
            "placeholder": "​",
            "style": "IPY_MODEL_f626f1da97bb4f219a222454aa9c2d01",
            "tabbable": null,
            "tooltip": null,
            "value": " 570/570 [00:00&lt;00:00, 22.3kB/s]"
          }
        },
        "a179bb9b77fd41a3abbaf872d2fb48ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "2.0.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_4eb74448c4fa4047870077499f718f05",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dfd3f3db9bd9421bb50398f51fa79f8b",
            "tabbable": null,
            "tooltip": null,
            "value": 231508
          }
        },
        "ab9aec9ff9cb42c1b87dd61b314bd749": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "2.0.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf1cabd964e54b888783a9945e2d4d67": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "2.0.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c2d987de25b647e6a37faf5e4568f8da": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "2.0.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2fd4c41d84684d1d83347b65f03e6876",
              "IPY_MODEL_a179bb9b77fd41a3abbaf872d2fb48ff",
              "IPY_MODEL_f2f2d791eed44f42992d5b8be7548a83"
            ],
            "layout": "IPY_MODEL_ab9aec9ff9cb42c1b87dd61b314bd749",
            "tabbable": null,
            "tooltip": null
          }
        },
        "d2c304b04aeb4fbcb415abe88040acff": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "2.0.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dfd3f3db9bd9421bb50398f51fa79f8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "2.0.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dfd73627ead44fc9a900fca628a723c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "2.0.0",
          "model_name": "HTMLStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "e0aa2cda97ee4a3da7f96e56b391c8cd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "2.0.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5015dd930e548b3ba5e9de78299be43": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "2.0.0",
          "model_name": "HTMLStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "ef035f8849f749b4aeb858cbf5aa0aca": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "2.0.0",
          "model_name": "HTMLStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "f2f2d791eed44f42992d5b8be7548a83": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "2.0.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_fe0b3ef0c853434aa7ec90e0a6dc0926",
            "placeholder": "​",
            "style": "IPY_MODEL_e5015dd930e548b3ba5e9de78299be43",
            "tabbable": null,
            "tooltip": null,
            "value": " 226k/226k [00:00&lt;00:00, 564kB/s]"
          }
        },
        "f626f1da97bb4f219a222454aa9c2d01": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "2.0.0",
          "model_name": "HTMLStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "fd7f16ff553644d7aa4417df1aa2e6bd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "2.0.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe0b3ef0c853434aa7ec90e0a6dc0926": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "2.0.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
